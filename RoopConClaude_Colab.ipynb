{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ ROOP Batch Processor - Google Colab\n",
    "\n",
    "**Ejecuta las celdas en orden. La celda 1 puede pedir reinicio.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==========================================\n# üì¶ CELDA 1: Instalaci√≥n limpia CUDA\n# ==========================================\n\n# Clonar repo\n!git clone https://github.com/CDavidDv/RoopConClaude.git 2>/dev/null || echo \"Ya clonado\"\n%cd /content/RoopConClaude\n\n# LIMPIAR TODO\n!pip uninstall -y onnxruntime onnxruntime-gpu insightface -q 2>/dev/null || true\n\n# Instalar requirements headless\n!pip install -r requirements-headless.txt -q\n\n# Instalar ONNX GPU primero (IMPORTANTE: GPU antes que CPU)\n!pip install onnxruntime-gpu==1.18.0 -q\n\n# Luego InsightFace\n!pip install insightface==0.7.3 -q\n\n# TensorFlow y NumPy compatibles\n!pip install tensorflow==2.12.0 numpy==1.23.5 -q\n\n# CUDA library\n!apt-get update -qq\n!apt-get install -y -qq libcufft10 2>/dev/null || true\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"‚úÖ Instalaci√≥n completada\")\nprint(\"=\"*50)\nprint(\"\\n‚ö†Ô∏è  Reinicia el runtime si hay errores:\")\nprint(\"   Runtime > Restart runtime\")\nprint(\"   Luego ejecuta CELDA 2\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üîç CELDA 2: Verificar instalaci√≥n\n",
    "# ==========================================\n",
    "\n",
    "%cd /content/RoopConClaude\n",
    "\n",
    "import numpy as np\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "\n",
    "import onnxruntime as ort\n",
    "print(f\"ONNX Providers: {ort.get_available_providers()}\")\n",
    "\n",
    "import insightface\n",
    "app = insightface.app.FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "print(\"‚úÖ InsightFace con CUDA listo\")\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Todo listo! Contin√∫a con CELDA 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üì§ CELDA 3: Subir archivos\n",
    "# ==========================================\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "%cd /content/RoopConClaude\n",
    "!mkdir -p source inputVideos outputVideos\n",
    "\n",
    "print(\"üì∏ Sube tu imagen de referencia:\")\n",
    "uploaded = files.upload()\n",
    "for f in uploaded:\n",
    "    os.rename(f, f\"source/{f}\")\n",
    "    print(f\"‚úÖ source/{f}\")\n",
    "\n",
    "print(\"\\nüé¨ Sube tus videos:\")\n",
    "uploaded = files.upload()\n",
    "for f in uploaded:\n",
    "    os.rename(f, f\"inputVideos/{f}\")\n",
    "    print(f\"‚úÖ inputVideos/{f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Archivos listos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üöÄ CELDA 4: Procesar videos\n",
    "# ==========================================\n",
    "\n",
    "%cd /content/RoopConClaude\n",
    "\n",
    "# Procesar TODOS los videos\n",
    "!python runbatch.py\n",
    "\n",
    "# O procesar un RANGO (descomenta):\n",
    "# !python runbatch.py 1-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üì• CELDA 5: Descargar resultados\n",
    "# ==========================================\n",
    "\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "%cd /content/RoopConClaude\n",
    "\n",
    "for video in sorted(Path('outputVideos').glob('*.mp4')):\n",
    "    print(f\"‚¨áÔ∏è {video.name}\")\n",
    "    files.download(str(video))\n",
    "\n",
    "print(\"\\n‚úÖ Descarga completada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üì§ EXTRA: Subir m√°s videos\n",
    "# ==========================================\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "%cd /content/RoopConClaude\n",
    "\n",
    "print(\"üé¨ Sube m√°s videos:\")\n",
    "uploaded = files.upload()\n",
    "for f in uploaded:\n",
    "    os.rename(f, f\"inputVideos/{f}\")\n",
    "    print(f\"‚úÖ inputVideos/{f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}