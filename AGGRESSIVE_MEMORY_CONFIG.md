# Configuraci√≥n Agresiva de Memoria para T4 (Google Colab)

## Tu Sistema
- **RAM**: 12 GB
- **GPU VRAM**: 15 GB (T4)
- **Objetivo**: Procesar 65 videos lo m√°s r√°pido posible

## Cambios Realizados ‚úÖ

### 1. **TensorFlow GPU Limit** (core.py:99)
```python
# ANTES: 10.24 GB
memory_limit=10240

# AHORA: 13.31 GB (dejando 1.7GB de margen)
memory_limit=13312
```
**Impacto**: +3GB de VRAM disponible para face swapper/enhancer

### 2. **Par√°metros Agresivos** (runbatch.py)
```bash
# ANTES
--max-memory 8
--execution-threads 4

# AHORA
--max-memory 11
--execution-threads 6
```
**Impacto**: Usar 11GB RAM + mayor paralelismo CUDA

### 3. **Nuevo: Procesamiento Paralelo** (runbatch_parallel.py)
```bash
# Procesar 2 videos simult√°neamente
python runbatch_parallel.py --parallel 2
```
**Impacto**: ~40-50% m√°s r√°pido (8-10 horas en lugar de 11-15)

## Modos de Uso

### Opci√≥n A: Serial Optimizado (RECOMENDADO para estabilidad)
```bash
# Uno a la vez, pero con m√°s memoria
python runbatch.py

# Resultado esperado:
# - 65 videos en ~10-12 horas
# - Muy estable, sin riesgo de OOM
# - Uso: RAM 8-10GB, VRAM 12-13GB
```

### Opci√≥n B: Paralelo Agresivo (M√ÅS R√ÅPIDO)
```bash
# 2 videos simult√°neos
python runbatch_parallel.py --parallel 2

# Resultado esperado:
# - 65 videos en ~6-8 horas
# - Mayor riesgo de OOM si hay picos
# - Uso: RAM 11-12GB, VRAM 13-14GB
```

### Opci√≥n C: S√∫per Paralelo (RIESGO ALTO)
```bash
# 3 videos simult√°neos (EXPERIMENTAL)
python runbatch_parallel.py --parallel 3

# ‚ö†Ô∏è ADVERTENCIA:
# - Alto riesgo de crash por OOM
# - Solo si realmente necesitas m√°xima velocidad
# - Solo en Colab (ambiente controlado)
```

## Comparaci√≥n de Rendimiento

| Modo | Velocidad | RAM | VRAM | Riesgo | Tiempo 65 vids |
|------|-----------|-----|------|--------|----------------|
| Original (8GB/4t) | 1x | 8GB | 10GB | Bajo | 15h |
| **Optimizado (11GB/6t)** | **1.3x** | **10GB** | **13GB** | **Bajo** | **12h** |
| Paralelo 2x | **1.8x** | **11GB** | **13GB** | **Medio** | **8h** |
| Paralelo 3x | **2.2x** | **12GB** | **14GB** | **Alto** | **7h** |

## Monitoreo en Tiempo Real (Google Colab)

En otra celda ejecuta esto para ver m√©tricas:

```python
import subprocess
import time
import psutil

while True:
    # RAM
    ram = psutil.virtual_memory()
    print(f"RAM: {ram.used/1e9:.1f}GB / {ram.total/1e9:.1f}GB ({ram.percent:.1f}%)")

    # GPU (si nvidia-smi disponible)
    try:
        gpu_out = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,nounits,noheader'], text=True)
        used, total = map(float, gpu_out.strip().split(','))
        print(f"GPU: {used/1024:.1f}GB / {total/1024:.1f}GB ({used/total*100:.1f}%)")
    except:
        pass

    print("-" * 40)
    time.sleep(5)
```

## Qu√© Hacer Si Crashea

### OOM (Out of Memory) Error
```bash
# 1. Reducir a serial mode
python runbatch.py

# 2. Si sigue crashing, reducir memoria
# Editar runbatch.py l√≠nea 126:
--max-memory 9
--execution-threads 4

# 3. Reiniciar kernel de Colab (limpia memoria)
# Kernel ‚Üí Restart runtime
```

### CUDA Out of Memory
```bash
# Opci√≥n A: Reducir batch size en core.py:99
memory_limit=11264  # De 13312

# Opci√≥n B: Solo usar face_swapper (sin enhancer)
--frame-processor face_swapper

# Opci√≥n C: Reducir calidad
--temp-frame-quality 80
--output-video-quality 15
```

## Configuraci√≥n Segura para Colab Durantes Largas Ejecuciones

Si vas a procesar sin monitoreo (ej: de noche):

```bash
# Versi√≥n ultra-estable (pero m√°s lenta)
python runbatch.py

# Editar par√°metros a:
--max-memory 9          # Margen de seguridad
--execution-threads 4
```

Con esto:
- No deber√≠a crashear
- ~1 video cada 10 minutos
- 65 videos en ~11 horas

## Optimizaci√≥n por Rango

Si quieres m√°ximo control, procesa en tandas:

```bash
# Tanda 1: Primeros 20 (paralelo 2x)
python runbatch_parallel.py --parallel 2 1-20

# Tanda 2: Siguiente 20
python runbatch_parallel.py --parallel 2 21-40

# Tanda 3: √öltimos 25
python runbatch_parallel.py --parallel 2 41-65
```

**Ventajas**:
- Menor riesgo de mega-crash
- Puedes cambiar par√°metros entre tandas
- Seguimiento m√°s granular

## Benchmarks Esperados (T4 + 12GB RAM)

### Video t√≠pico: 30 segundos, 720p, 30fps
- **Face swapper**: ~50 segundos
- **Face enhancer**: ~40 segundos
- **Encoding**: ~30 segundos
- **Total por video**: ~2 minutos

### Con face_swapper solo (sin enhancer)
- **Total por video**: ~1.5 minutos

### Paralelo 2x (2 videos simult√°neos)
- **Throughput**: 1 video cada 2 minutos
- **Para 65 videos**: ~2 minutos √ó 33 = ~66 minutos = 1.1 hora (te√≥rico)

En pr√°ctica real:
- Overhead de filesystem: +10%
- Limpieza de temp frames: +5%
- Variabilidad de tama√±o video: ¬±20%
- **Resultado real**: 1 video cada 2.5-3 minutos = 6-8 horas

## Logs Esperados (Modo Agresivo)

```
üìä Sistema: 12.0GB RAM disponibles
üìä GPU: T4 con ~15GB VRAM
---
üíæ Memoria antes: 2.3GB
üíæ Memoria despu√©s: 2.1GB (diferencia: -0.2GB)
üìä RAM: 9.5GB | GPU: 12.8GB  ‚Üê Presionado pero estable
üßπ Limpiado: roop/temp_xxxxxxxx
```

## Troubleshooting

| S√≠ntoma | Causa | Soluci√≥n |
|---------|-------|----------|
| `CUDA OOM` | GPU sin suficiente VRAM | Reducir threads, usar face_swapper solo |
| `Malloc error` | RAM agotada | Reducir --max-memory, serial mode |
| Proceso lento | Swapping a disco | Reducir parallelismo |
| Intermitente crash | Fuga de memoria | Actualizar TensorFlow/ONNX |

## Configuraci√≥n Final Recomendada

**Para m√°ximo rendimiento en Colab (sin riesgo de crash):**

```bash
python runbatch.py
# Con valores: --max-memory 11, --execution-threads 6
# Resultado: ~12 horas para 65 videos, muy estable
```

**Si necesitas ir m√°s r√°pido y aceptas riesgo:**

```bash
python runbatch_parallel.py --parallel 2
# Resultado: ~8 horas, riesgo medio
# Monitorea RAM/GPU en otra celda
```

---

**Actualizado**: 2026-01-08
**Optimizado para**: Google Colab T4 (15GB VRAM, 12GB RAM)
